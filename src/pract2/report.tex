\graphicspath{{./img/}}
\section*{ЦЕЛЬ ПРАКТИЧЕСКОЙ РАБОТЫ}
\addcontentsline{toc}{section}{ЦЕЛЬ ПРАКТИЧЕСКОЙ РАБОТЫ}

Prometheus --- это система мониторинга и сбора метрик,
разработанная для обеспечения надежности и производительности приложений.
Она использует модель временных рядов для хранения данных
и поддерживает язык запросов PromQL для анализа метрик.

Ключевые особенности:

\begin{itemize}
    \item Сбор метрик: Регулярный пулл данных с различных источников.
    \item PromQL: Язык для создания запросов и анализа метрик.
    \item Гибкость: Масштабируемая и интегрируемая
    с инструментами визуализации, такими как Grafana.
    \item Алертинг: Настройка оповещений через Alertmanager
    для мониторинга критических состояний.
\end{itemize}

Prometheus помогает эффективно отслеживать состояние систем
и принимать меры для их оптимизации и поддержания.

\textbf{Цель работы} --- познакомится с системой мониторинга
и сбора метрик Prometheus.

\clearpage

\section*{ВЫПОЛНЕНИЕ ПРАКТИЧЕСКОЙ РАБОТЫ}
\addcontentsline{toc}{section}{ВЫПОЛНЕНИЕ ПРАКТИЧЕСКОЙ РАБОТЫ}

\section{Описание тестового стенда,
    листинги Dockerfile, docker-compose.yml, prometheus.yml,
    исходного кода web-приложения}

\subsection{Web-приложение на FastAPI с метриками Prometheus}

Создадим новый Python-проект и установим нужные библиотеки:
\texttt{fastapi}, \texttt{uvicorn}, \texttt{prometheus-fastapi-instrumentator}.

\lstinputlisting[
    language=Python, caption=\leftline{Код приложения}
]{2/main.py}

Это простейшее FastAPI-приложение с одним маршрутом \texttt{"/"}
и встроенным сбором метрик Prometheus через библиотеку
\texttt{prometheus-fastapi-instrumentator}.

\clearpage

\subsection{Dockerfile}

Создадим файл Dockerfile для сборки контейнера с приложением.

\lstinputlisting[caption=\leftline{Dockerfile}]{2/Dockerfile}

\subsection{prometheus.yml}

Создадим файл \texttt{prometheus.yml},
в котором будут указаны адреса сбора метрик с FastAPI-приложения и cAdvisor.

\lstinputlisting[caption=\leftline{prometheus.yml}]{2/prometheus.yml}

В нем указаны:

\begin{itemize}
    \item \textbf{fastapi-app}: адрес FastAPI-приложения,
    которое собирает метрики на \texttt{/metrics};
    \item \textbf{cadvisor}: адрес cAdvisor,
    который собирает метрики о контейнерах;
    \item \textbf{scrape\_interval}: интервал сбора метрик 15 секунд.
\end{itemize}

\subsection{docker-compose.yml}

Для запуска 4 контейнеров (Web-приложение, cAdvisor, Prometheus и Grafana)
с помощью Docker Compose, нужно создать \texttt{docker-compose.yml}
с конфигурацией для всех указанных сервисов.

\lstinputlisting[
    caption=\leftline{docker-compose.yml}
]{2/docker-compose.yml}

Стоит отметить следующий особенности конфигурации:

\begin{itemize}
    \item К \textbf{cAdvisor (cadvisor)} монтируются системные директории
    для сбора данных о контейнерах и хосте;
    \item В \textbf{Prometheus (prometheus)}
    используется внешний файл конфигурации prometheus.yml,
    который был описан ранее;
    \item Для \textbf{Grafana (grafana)}
    создается постоянный том \texttt{grafana-storage}
    для хранения данных Grafana;
    \item Для всех контейнеров установлено ограничение на cpu и ram.
\end{itemize}

\subsection{Запуск контейнеров}

Для запуска контейнеров используется команда \verb|docker-compose up --build|.
После запуска будут доступны следующие сервисы:

\begin{itemize}
    \item FastAPI Web-приложение: \url{http://0.0.0.0:8000/};
    \item cAdvisor: \url{http://0.0.0.0:8080};
    \item Prometheus: \url{http://0.0.0.0:9090};
    \item Grafana: \url{http://0.0.0.0:3000}.
\end{itemize}

\clearpage
\section{Скриншоты настроенного дашборда,
    параметры проведения нагрузочного тестирования}

\subsection{Grafana Dashboard}

После того, как Grafana запущена, нужно добавить Prometheus
в качестве источника данных \rref{fig:data-source:add}.

\begin{image}
    \includegrph{prom-conf-con}
    \caption{Добавление Data Source}
    \label{fig:data-source:add}
\end{image}

Теперь можно создать дашборд с необходимыми графиками.
Первый график будет показывать количество HTTP-запросов, поступивших на веб-приложение (\rref{fig:graph:requests}).
Для этого используется метрика \verb|http_requests_total|.
Мы применим операцию Delta, чтобы отслеживать нагрузку на сервис в реальном времени.

\begin{image}
    \includegrph{requests-total}
    \caption{График с количеством HTTP-запросов}
    \label{fig:graph:requests}
\end{image}

Далее создадим график, отображающий загрузку CPU контейнера с веб-приложением, данные для которого будут поступать из
cAdvisor (\rref{fig:graph:cpu}).
Для этого используется метрика \verb|container_cpu_load_average_10s|,
которая показывает среднюю нагрузку на процессор за последние 10 секунд для контейнера с именем \verb|2_webapp_1|.

\begin{image}
    \includegrph{graph-cpu}
    \caption{График с утилизацией CPU контейнера с веб-приложением}
    \label{fig:graph:cpu}
\end{image}
\clearpage

Последний график будет показывать использование оперативной памяти контейнера с веб-приложением, с данными,
поступающими из cAdvisor (\rref{fig:graph:ram}).
Для этого используется метрика \verb|container_memory_usage_bytes| для контейнера с именем \verb|2_webapp_1|.
Для отображения в мегабайтах значение дважды делится на 1024, чтобы перевести байты в мегабайты.

\begin{image}
    \includegrph{graph-ram}
    \caption{График с утилизацией RAM контейнера с веб-приложением}
    \label{fig:graph:ram}
\end{image}


После добавления всех графиков сохраняем изменения, и дашборд с визуализациями теперь доступен для мониторинга
запросов, а также использования CPU и оперативной памяти контейнера с веб-приложением.

\begin{image}
    \includegrph{dashboard}
    \caption{Полученый дашборд}
    \label{fig:dashboard}
\end{image}

\subsection{Docker stats}


Для независимого контроля за использованием ресурсов контейнеров, включая контейнер с web-приложением, можно воспользоваться командой
\texttt{docker stats} или \texttt{docker stats 2\_webapp\_1} для получения данных по конкретному контейнеру.
Эта команда в реальном времени выводит статистику по каждому запущенному контейнеру ( \rref{fig:docker-stats}).

\begin{image}
    \includegrph{docker-stats}
    \caption{Полученый дашборд}
    \label{fig:docker:stats}
\end{image}

Вывод команды \texttt{docker stats} включает:

\begin{itemize}
    \item CPU --- процент использования CPU контейнером.
    \item MEM USAGE / LIMIT --- объем используемой памяти и ее лимит.
    \item MEM --- процент использования памяти от доступного лимита.
    \item NET I/O --- количество данных, переданных и полученных по сети.
    \item BLOCK I/O --- количество операций ввода-вывода с диском.
    \item PIDS --- количество процессов в контейнере.
\end{itemize}


\section{Проведение нагрузочного тестирования, анализ полученных результатов}

Для проведения нагрузочного тестирования веб-приложения и определения максимального количества запросов, которые оно
может обработать до отказа, будет использоваться Apache JMeter.

\subsection{Установка Apache JMeter}

Для установки приложения Apache JMeter в Ubuntu воспользуемся командой
\texttt{sudo apt install jmeter} \rref{fig:jmeter:install}.

\begin{image}
    \includegrph{jmeter-install}
    \caption{Установка Apache JMeter}
    \label{fig:jmeter:install}
\end{image}

\subsection{Настройка теста в JMeter}

В начале нужно создать группу потоков.
В нем настраиваем следующие параметры \rref{fig:jmeter:thread:group}:

\begin{itemize}
    \item \textbf{Number of Threads (Users)}:
    количество виртуальных пользователей;
    \item \textbf{Ramp-Up Period (in seconds)}: время,
    за которое все потоки запустятся;
    \item \textbf{Loop Count}: количество итераций для каждого потока.
\end{itemize}

\begin{image}
    \includegrph{jmeter-thread-group}
    \caption{Настройка группы потоков}
    \label{fig:jmeter:thread:group}
\end{image}

Далее нужно добавить HTTP-запроса. В нем указываем
URL web-приложения, порт и путь к странице \rref{fig:jmeter:http}.

\begin{image}
    \includegrph{jmeter-http}
    \caption{Настройка HTTP-запроса}
    \label{fig:jmeter:http}
\end{image}

Также нужены:

\begin{itemize}
    \item \texttt{HTTP Header Manager} для установки заголовков запроса.
    В нем добавим заголовок Content-Type: application/json;
    \item \texttt{Listener} для визуализации результатов тестирования.
\end{itemize}

\subsection{Анализ результатов}

Максимальное количество запросов, которое приложение смогло обработать, составило \textbf{400} запросов в минуту.

\begin{image}
    \includegrph{run}
    \caption{Результаты тестирования}
    \label{fig:run}
\end{image}

\clearpage

\section*{\LARGE ВЫВОД}
\addcontentsline{toc}{section}{ВЫВОД}

В рамках практической работы было проведено нагрузочное тестирование веб-приложения на FastAPI с использованием
Apache JMeter для оценки производительности, а также Prometheus и Grafana для мониторинга системных метрик.
\par
В процессе тестирования был достигнут предельный уровень нагрузки на приложение, после чего оно перестало отвечать
на запросы, и передача метрик в Prometheus прекратилась.

\clearpage


\section{Ответы на контрольные вопросы}

\subsection{Типы метрик в Prometheus и их применение}

В Prometheus выделяют четыре основных типа метрик, каждая из которых служит для различных целей мониторинга и анализа:


\textbf{Counter (Счетчик)}: \par
\textbf{Описание}: Это метрика, которая увеличивается со временем.
Счетчики используются для отслеживания количества событий, таких как количество обработанных запросов
или количество ошибок. \par
\textbf{Применение}: Счетчики идеально подходят для событий, которые происходят один раз и никогда не уменьшаются,
например, число HTTP-запросов или число завершенных задач. \par

\textbf{Gauge (Манометр)}:\par
\textbf{Описание}: Эта метрика может увеличиваться или уменьшаться. Она используется для представления значений, которые могут изменяться в любое время, например, использование памяти или загрузка CPU.\par
\textbf{Применение}: Гаужи полезны для мониторинга таких метрик, как текущее количество активных соединений, использование оперативной памяти или температура.\par

\textbf{Histogram (Гистограмма)}:\par
\textbf{Описание}: Гистограммы позволяют собирать данные о распределении значений. Они измеряют значения и группируют их в определенные интервалы (бакеты), что позволяет отслеживать, как часто происходят события в этих диапазонах.\par
\textbf{Применение}: Гистограммы используются для анализа времени отклика или размерности объектов, например, для мониторинга времени обработки запросов и выявления задержек.\par

\textbf{Summary (Резюме)}:\par
\textbf{Описание}: Резюме также используется для сбора данных о распределении значений, но в отличие от гистограмм, они обеспечивают более детальную информацию, включая квантильные значения (например, 50-й или 95-й процентиль) и общее количество наблюдений.\par
\textbf{Применение}: Резюме часто применяются для измерения времени отклика или других метрик, где важно знать не только распределение, но и ключевые процентильные значения.\par

Каждый из этих типов метрик позволяет мониторить различные аспекты системы и эффективно собирать данные, что помогает в анализе производительности, выявлении узких мест и принятии решений о масштабировании или оптимизации.

\subsection{Использование Pushgateway приложений для Prometheus}

Pushgateway используется для сценариев, в которых приложения или процессы не могут постоянно поддерживать связь
с Prometheus для экспорта метрик.
Вместо того чтобы Prometheus периодически запрашивал метрики у приложений, Pushgateway позволяет приложениям отправлять
(push) свои метрики в промежуточный буфер (Pushgateway), откуда уже Prometheus забирает эти данные.

Основные случаи использования Pushgateway:

Краткосрочные или одноразовые задачи:
Для приложений, которые выполняются быстро (например, batch-скрипты), и не имеют времени на установление постоянного
соединения с Prometheus.
Асинхронные или фоновые задачи: Если задача завершается до следующего сбора данных Prometheus,
метрики могут быть потеряны.
Pushgateway решает эту проблему, сохраняя метрики до того, как они будут запрошены.
Однако, Pushgateway не рекомендуется для долгоживущих процессов, которые могут напрямую взаимодействовать
с Prometheus через стандартную модель\( "\)pull\("\), так как это нарушает принцип pull-модели сбора данных Prometheus.

\subsection{Хранение данных в системе Prometheus}

В системе Prometheus данные хранятся в виде временных рядов (time series), которые состоят из метрик, значений и меток
(labels), используемых для их идентификации.
Временные ряды сохраняются в базе данных, встроенной в Prometheus.

Основные особенности хранения данных в Prometheus:
Временные ряды: Каждый временной ряд представляет собой метрику с уникальной комбинацией имени и меток.
Например, метрика http\_requests\_total с меткой {method=\("\)GET\("\), status=\("\)200\("\)}.

Хранилище (TSDB): Prometheus использует Time Series Database (TSDB) для хранения данных временных рядов.
Данные организованы в блоки, которые создаются каждые 2 часа.
Каждый блок содержит сжатую информацию о временных рядах, хранящуюся в формате \("\)ключ-значение\("\) и
разделенную по временным интервалам.

Retention (срок хранения): Данные хранятся в Prometheus в течение заданного времени (по умолчанию 15 дней), после чего
они удаляются.
Период хранения можно изменить в конфигурации Prometheus.

Сегментация и сжатие данных: Prometheus использует эффективные алгоритмы сжатия данных (например, алгоритм Gorilla) для
уменьшения объема хранимых данных и оптимизации запросов.
Данные агрегируются и сжимаются для снижения нагрузки на хранилище.

Remote Storage (удаленное хранилище): Для длительного хранения данных можно использовать удаленное хранилище,
совместимое с Prometheus, например Thanos, Cortex или другие.
В этом случае Prometheus отправляет данные во внешнее хранилище, где они могут храниться дольше и использоваться для
аналитики или отчетности.

Таким образом, Prometheus оптимизирован для хранения краткосрочных данных с возможностью отправки в удаленные системы
для долгосрочного хранения и анализа.

\subsection{Основные конструкции языка PromQL}

Вот основные конструкции языка PromQL, оформленные с помощью LaTeX:

1. Выборка метрик:
- Запросы можно формировать с использованием имен метрик, например:
\[
    \texttt{http\_requests\_total}
\]

2. Фильтрация по меткам:
- Вы можете фильтровать временные ряды по меткам, используя конструкцию \texttt{сравнение}:
\[
    \texttt{http\_requests\_total\{method="GET"\}}
\]

3. Агрегация:
- PromQL поддерживает агрегацию по меткам с использованием функций, таких как \texttt{sum}, \texttt{avg}, \texttt{max}, \texttt{min}, \texttt{count} и других:
\[
    \texttt{sum(http\_requests\_total)}
\]
\[
    \texttt{avg(http\_response\_time\_seconds)}
\]

4. Операторы:
- Поддерживаются арифметические операции (\(+\), \(-\), \(*\), \(/\)), а также операции сравнения (\(>\), \(<\), \(==\), \(!=\), \(\geq\), \(\leq\)). Пример:
\[
    \texttt{http\_requests\_total\{status="200"\} / http\_requests\_total}
\]

5. Функции:
- PromQL включает множество встроенных функций для обработки временных рядов, таких как \texttt{rate}, \texttt{increase}, \texttt{irate}, \texttt{count\_over\_time}, \texttt{avg\_over\_time} и другие. Например:
\[
    \texttt{rate(http\_requests\_total[5m])}
\]

6. Срезы (range vectors):
- Срезы позволяют работать с временными рядами за определенный промежуток времени, например:
\[
    \texttt{http\_requests\_total[10m]}
\]

7. Литералы и выражения:
- PromQL поддерживает использование литералов, таких как числа и строки. Примеры выражений:
\[
    \texttt{http\_requests\_total > 1000}
\]

8. Подзапросы:
- Вы можете использовать подзапросы для более сложных вычислений, например:
\[
    \texttt{sum(rate(http\_requests\_total[5m])) by (status)}
\]

9. Объединение временных рядов:
- PromQL позволяет объединять временные ряды с разными метками с использованием операторов \(*\), \(+\), и \(-\), например:
\[
    \texttt{http\_requests\_total\{method="GET"\} + http\_requests\_total\{method="POST"\}}
\]

10. Логические операции:
- Логические операции \(\texttt{and}\), \(\texttt{or}\), и \(\texttt{unless}\) могут быть использованы для объединения временных рядов:
\[
    \texttt{http\_requests\_total\{method="GET"\} \texttt{and} http\_requests\_total\{status="200"\}}
\]

Эти конструкции позволяют пользователям Prometheus выполнять сложные запросы для получения необходимых данных, анализа производительности и мониторинга систем в реальном времени.